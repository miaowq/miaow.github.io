---
title: 消费者｜事务
categories:
  - mq
tags:
  - mq
  - kafka
abbrlink: 62f2fda0
date: 2023-12-08 23:00:08
---

> 本系列内容基于 kafka_2.12-2.3.1

# 消息传输保障

一般 言，消息中间件的消息传输保障有 个层级，分别如下。
- `at most once`  至多一次。消息可能会丢失，但绝对不会重复传输。
- `at least once` 最少一次。消息绝不会丢失，但可能会重复传输。
- `exactly once`  恰好一次。每条消息肯定会被传输一次且仅传输一次。

<!-- more -->

## Kafka视角
Kafka 提供的消息传输保障机制为 atleast once。

发送消息时，一旦消息被提交到日志中，由于多副本机制的存在，这条消息就不会丢失。

而如果发送了网络问题，生产者无法判断该消息是否已经提交。虽然无法确认这个期间发送了什么，但有 重试机制进行保障，只是这个机制会带来重复消费。

## 消费者视角

**先处理逻辑，再提交位移**

at least one 如果提交前宕机了，会从上一次的位移开始消费，导致重复消费

**先提交位移，再处理逻辑**

at most once 如果提交位移后宕机了，没有执行预期的逻辑，导致消息丢失

因此，Kafka 在0.11.0.0 开始引入了 `幂等` 和 `事务` 两大特性，以此来实现 `EOS` `exactly once semantics` ，精确一次处理语义。

# 幂等

所谓的幂等，简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。

## 配置

在 kafka-go 中没有显示的设置，需要自行保证。

在Java中，由多个参数共同保证

- `enable.idempotence` 设置为 true
- retries 如果设置了则必须大于0，否则会设置为 integer.MAX_VALUE
- max.in.flight.requests.per.connection 不能大于5
- acks 必须为 -1

## Kafka视角

为了保证幂等性，引入了 procuer id 和 序列号。

每个新的生产者实例在初始化的时候都会被分配一个 ID，这个 PID 对用户而言是完全透明的。

对于每个 PID 消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。

内存中的每一对 <PID, 分区号> 维护一个序列号，有新的消息时，它的序列号比维护的序列号 大1 才会被接收，否则丢弃。

所以：

**引入序列号来实现幕,也只是针对每一对＜PID, 分区＞而言的。**

**也就是说，Kafka 的幂等只能保证单个生产者会话中单分区的事等**

# 事务

`幂等` 并不能跨多个分区运作，而 `事务` 可以弥补这个缺陷。

事务可以保证对多个分区写入操作的原子性。

对 流式应用 而言，一个典型的应用模式为 `consume - transform - produce` 。在这种模式下消费和生产并存：应用程序从某个主题中消费消息，然后经过一系列转换后写入另一个主题，消费者可能在提交消费位移的过程中出现问题而导致重复费，也有可能生产者重复生产消息。

Kafka 中的事务可以使应用程序将消费消息、生产消息、提交消费位移当作原子操作来处理，同时成功或失败，即使该生产或消费会跨多个分区。

## 必备配置

为了实现事务，应用程序必须提供唯一的 transactionalld ；还要求生产者开启幕等特性。

## 生产者角度

**可以保证跨生产者会话的消息幕等发送**

具有相同 transactionalld 新生产者实例被创建且工作的时候，旧的且拥有相同 transactionalld 的生产者实例将不再工作。

**跨生产者会话的事务恢复**

当某个生产者实例君机后，新的生产者实例可以保证任何未完成的旧事务要么被提交，要么被中止，如此可以使新的生产者实例从一个正常的状态开始工作。

## 消费者角度

**事务能保证的语义相对偏弱**

出于以下原因， Kafka 并不能保证己提交的事务中的所有消息都能够被消费：

- 对采用日志压缩策略的主题而言，事务中的某些消息有可能被清理（相同 key 的消息，后写入的消息会覆盖前面写入的消息）。
- 事务中消息可能分布在同一个分区的多个日志分段（ LogSegment ）中，当老的日志分段被删除时，对应的消息可能会丢失。
- 消费者可以通过 seek 方法访问任意 offset 的消息，从而可能遗漏事务中的部分消息。
- 消费者在消费时可能没有分配到事务内的所有分区，如此它也就不能读取事务中的所
有消息。

## 隔离级别

**read_uncommitted**
消费端应用 可以消费到未提交的事务

**read_committed**
消费端应用 不可以消费到未提交的事务

## 控制消息

类型有 COMMIT 和 ABORT，分别用来表征事务己经成功提交或己经被成功中止。KafkaConsumer 可以通过这个控制消息来判断对应的事务是被提交了还是被中止了，然后结合参数 isolation.level 配置的隔离级别来决定是否将相应的消息返回给消费端应用

## 事务协调器

为了实现事务的功能， Kafka 还引入了 事务协调器 来负责处理事务，这一点可以类比一下组协调器。每一个生产者都会被指派一个特定的
事务协调器，所有的事务逻辑包括分配PID等都是由 事务协调器 来负责实施的。 事务协调器 会将事务状态持久化到内部主题 _transact on_state中。简述步骤：

1. 查找 TransactionCoordinator

TransactionCoordinator 责分配 PID 管理事务，因此生产者要做的第 件事情就是找出对应的 TransactionCoordinator 所在的broker 节点。

2. 获取PID

要为当前生产者分配一个 PID。

3. 开启事务

4. Consume-Transform-Produce

这个阶段囊括了整个事务的数据处理过程，其中还涉及多种请求。

5. 提交或者中止事务